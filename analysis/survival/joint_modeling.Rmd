---
title: "Joint Model Fitting"
output: html_document
date: "2023-12-12"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,  # don't print the code chunk
  warning = FALSE,  # don't print warnings
  message = FALSE,  # don't print messages
  fig.width = 8,  # set default width of figures
  fig.height = 5,  # set default height of figures
  fig.align = "center",  # always align figure in center
  fig.pos = "H",  # always plot figure at the exact location of the code chunk
  cache = FALSE)  # cache results

## libraries ##
library(tidyverse)
library(ggplot2)
library(magrittr)
library(ggthemr)
library(grid)
library(gtable)
library(gridExtra)
library(wesanderson)
library(ggsci)
library(zoo)
library(kableExtra)
library(lme4)
library(RColorBrewer)
library(doParallel)
library(parallel)
library(foreach)
library(here)
library(fs)
library(ggcorrplot)
library(viridis)
library(lmtest)
library(gt)
library(survminer)
library(survival)
library(effectsize)
library(scales)
library(JMbayes2)
library(caret)

## hand written functions ##
source(path(here(), "R", 'mutate_cond.R'))
source(path(here(), "R", "clean_behavioral_data.R"))
source(path(here(), "R", "create_distance_df.R"))
## plotting helpers ##
ggthemr("light")
getPalette = colorRampPalette(brewer.pal(17, "Set1"))

c25 <- c(
  "dodgerblue2", "#E31A1C", # red
  "green4",
  "#6A3D9A", # purple
  "#FF7F00", # orange
  "black", "gold1",
  "skyblue2", "#FB9A99", # lt pink
  "palegreen2",
  "#CAB2D6", # lt purple
  "#FDBF6F", # lt orange
  "gray70", "khaki2",
  "maroon", "orchid1", "deeppink1", "blue1", "steelblue4",
  "darkturquoise", "green1", "yellow4", "yellow3",
  "darkorange4", "brown"
)

# ## parallelization ##
# nCores <- 2
# registerDoParallel(nCores)

```

Okay, I need to come up with a model fitting framework. I will use DIC to compare models, but I need to figure out what my approach is for going through the different options.

First, I think we should add in Lives and possibly Score, because I know this definitely effects the players choices. Is it possible to include interactions within this framework, not sure.

Then I think I want to gather a full list of options for operationalizing reward and compare that in a couple of subjects. I think starting out with ~5 subjects is optimal because I don't have a good prior about whether or not people are solving it in the same way and if I move to a hierarcical modeling option then I have to disentangle how well the model is doing as parsing subejct variance as well as parsing the different reward options. 

Cognitive Strategies for Reward

* go out and get a certain amount of reward and then come back
* try to get as much reward as possible until the ghost gets to close and then turn around
* pay attention to how close the next reward is and how big it is

Possible quantifications of reward

* amount of dots remaining
* amount of points remaining
* discounted by distance number of points remaining 
* number of big rewards left, number of small rewards left
* 5 different variables for the distance to each reward
* 5 different variables for the amount each reward/ if it is remaining

In general variables should be mean-centered:

The Cox PH submodel can be formulated as

â„Žð‘–(ð‘¡)=â„Ž0(ð‘¡)exp(ð›¾ð‘‡ð‘¤ð‘–),

where â„Ž0(ð‘¡) is the baseline hazard function at time ð‘¡ and ð‘¤ð‘–is a vector of baseline predictors with corresponding regression coefficients ð›¾
The submodel has two distinct parts. First, â„Ž0(ð‘¡) describes the hazard (e.g., risk of the event occurring, given it has not yet occurred) when all covariates ð‘¤ð‘– have value zero. This baseline hazard function is assumed invariant across all individuals ( â„Ž0(ð‘¡) does not depend on ð‘–). 
Second, the effect parameters ð›¾ð‘‡ð‘¤ð‘–describe how the hazard varies as a function of the explanatory covariates ð‘¤ð‘–.


NOTES

Functions start to break if Thoriz is larger than the longest turn time!

Next to figure out, why does AUC, ROC chane so much with different Thoriz??

```{r load-data}

pilot_behave_data_clean <- read_csv(path(here(), "munge", "prolific", "cleaned_pilot_behavior.csv"))
pilot_game_data_clean <- read_csv(path(here(), "munge", "prolific", "cleaned_pilot_game_data.csv"))
pilot_game_data_distance <- read_csv(path(here(), "munge", "prolific", "cleaned_pilot_distance_data.csv"))
pilot_all_vars_df <- read_csv(path(here(), "munge", "prolific", "cleaned_pilot_across_trial_data.csv"))

```


## Random Permuted

check to make sure the shuffling works by comparing distance to ghost at turnaround in shuffled vs real


```{r random-time-series}

random_time_series <- function(n, low_val, high_val) {
  timeseries = numeric(n)
  timeseries[1] = sample(low_val:high_val, 1)
  
  for (i in 2:n) {
    change = sample(c(-2, 2), 1)
    
    # Check boundaries and adjust if necessary
    if (timeseries[i-1] + change < 0) {
      change = 2
    } else if (timeseries[i-1] + change > 100) {
      change = -2
    }
    
    timeseries[i] = timeseries[i-1] + change
  }
  return(timeseries)

}
# Plotting the timeseries
plot(random_time_series(50, 0, 100), type = 'l', ylim = c(0, 100), xlab = "Time", ylab = "Value")

```


```{r train-test-split}

current_subject <- "Subject_11"
permuted <- FALSE

## Prep DF for Joint Model Fitting and select predictor variables ##
joint_dist_df <- prep_joint_df(pilot_game_data_distance, current_subject, permuted)

## Create Test/Train ##
split_df <- joint_dist_df %>% select(trial_numeric, turnaround_time) %>% distinct()
split_index <- create_test_train(split_df, 123)
train_trials <- split_df[split_index, 'trial_numeric'] %>% pull(trial_numeric)
test_trials <- split_df[-split_index, 'trial_numeric'] %>% pull(trial_numeric)

prediction_time <- median(split_df$turnaround_time)
 
split_df %>%
  mutate(split = if_else(trial_numeric %in% train_trials, "train", "test")) %>%
  ggplot(., aes(x = turnaround_time, fill = split)) +
  geom_density(alpha = 0.5, color = "black") +
  geom_vline(xintercept = prediction_time, color = "black") +
  theme(panel.background = element_rect(fill = "white", colour = "black"))
  


```


```{r prep-long-surivval-df}

# longitudinal dfs
train_long_data <- joint_dist_df %>%
  filter(trial_numeric %in% train_trials)
test_long_data <- joint_dist_df %>%
  filter(trial_numeric %in% test_trials)

# survival dfs
cox_df <- create_survival_df(joint_dist_df)
train_cox_df <- cox_df %>%
  filter(trial_numeric %in% train_trials)
test_cox_df <- cox_df %>%
  filter(trial_numeric %in% test_trials)

```


```{r fit-models}
## fit the longitudinal, survival, and joint models and print the summaries
file_name <- paste0(current_subject, "_", as.character(permuted))
fit_joint_models(train_long_data, train_cox_df, "Subject_11_test")

```

```{r test-model-standard}

## load model ##
jm_fit <- readRDS(path(here(), "data", "joint_models", paste0(file_name, ".rds")))

### ROC/AUC ###
## ROC ##
roc <- tvROC(jm_fit, newdata = test_long_data, Tstart = .5, Thoriz = prediction_time, idVar = 'trial_numeric')
plot(roc)   
## AUC ##
tvAUC(jm_fit, newdata = test_long_data, Tstart = .5, Thoriz = prediction_time, idVar = 'trial_numeric')

### Calibration ###
toi <- prediction_time - .5
calibration_plot(jm_fit, newdata = test_long_data, Tstart = .5, Dt = toi, idVar = 'trial_numeric')
calibration_metrics(jm_fit, newdata = test_long_data, Tstart = .5, Dt = toi, idVar = 'trial_numeric')

### Brier Scores ###
tvBrier(jm_fit, newdata = test_long_data, Tstart = .5, Dt = toi, integrated = T)


```
```{r test-model-custom}
ggthemr("solarized")

test_three_trials <- test_long_data %>% 
  filter(trial_time < .5) %>%
  select(-turnaround_time, -EVENT)

test_preds <- predict(jm_fit, 
          newdata = test_three_trials, process = "event", return_newdata = TRUE, 
          idVar = "trial_numeric", times = seq(.5, 2.5, .05))

test_cox_df <- test_cox_df %>% rename(turntime_real = turnaround_time) %>% select(trial_numeric, turntime_real)
test_preds_true <- left_join(test_preds, test_cox_df, by = "trial_numeric")

test_preds_true <- test_preds_true %>%
  arrange(turntime_real) %>%
  mutate(trial_numeric = factor(trial_numeric, levels = unique(trial_numeric)))

# Now use 'numeric_for_color' for the color aesthetic in ggplot
plot <- ggplot(test_preds_true, aes(x = trial_time, y = pred_CIF, color = trial_numeric)) +
  geom_rect(aes(xmin=0, xmax=.5, ymin=0, ymax=1), fill = "lightgrey", alpha = .5, color = 'lightgrey') +
  geom_vline(aes(xintercept = turntime_real, color = trial_numeric, alpha = .7)) +
  geom_point() +
  scale_color_viridis_d() +  # Using Viridis color scale
  theme(panel.background = element_rect(fill = "white"),
        axis.text = element_text(color = "black", size = 12),
        axis.title = element_text(color = "black", size = 12),
        legend.position =  'none',
        plot.title  = element_text(color = "black", size = 16, face = "plain")) +
  ylim(0, 1) + xlim(0, 2.5) + labs(color = "Test Trial") +
  ggtitle("Prediction on held out trials") +
  labs(x = "Time", y = "Probability of Turning Around")
plot


test_preds_true %>%
  mutate(near_50 = abs(pred_CIF - .5)) %>%
  group_by(trial_numeric) %>%
  mutate(closest_to_50 = min(near_50)) %>%
  filter(closest_to_50 == near_50) %>%
  mutate(turntime_pred = trial_time) %>%
  ungroup() %>%
  select(trial_numeric, turntime_real, turntime_pred) %>%
  distinct() %>%
  ggplot(., aes(x = turntime_real, y = turntime_pred)) +
  geom_point(size = 4) +
  theme(panel.background = element_rect(fill = "white")) +
  labs(x = "True Turnaround Time", y = "Predicted Turnaround Time") +
  ylim(.5, 2) + xlim(.5, 2)


```































